{
    "contents" : "#################\n# LOAD PACKAGES #\n#################\n\nrequire(mvtnorm) #for sampling from multivariate normal\nrequire(ggplot2) #for plotting\nrequire(BMA) #Adrian Raftery's Bayesian Model Averaging Package\nrequire(dplyr) #for transforming data\nrequire(magrittr) #for coding semantics\nrequire(corrplot)\nrequire(randomForest)\n\nset.seed(83749724) #true model\n\n###################################\n# TRUE MODEL FOR eae              #\n# THE IN-CONTEXT ACTOR EVALUATION #\n###################################\n\n\n#Model coefficients\n#coefficients taken from Lynn's book\nsim.B = c(\"intercept\" = -0.098, \n          \"ae\" = 0.47, \n          \"ap\" = 0, \n          \"aa\" = 0, \n          \"be\" = 0.425, \n          \"bp\" = -0.069, \n          \"ba\" = -0.106, \n          \"oe\" = 0.055, \n          \"op\" = 0,\n          \"oa\" = 0, \n          \"ae.be\" = 0.048,\n          \"ae.bp\" = -0.038,\n          \"ae.ba\" = 0,\n          \"ae.oe\" = 0, \n          \"ae.op\" = 0, \n          \"ae.oa\" = 0, \n          \"ap.be\" = 0, \n          \"ap.bp\" = 0, \n          \"ap.ba\" = 0, \n          \"ap.oe\" = 0, \n          \"ap.op\" = 0, \n          \"ap.oa\" = 0, \n          \"aa.be\" = 0.048, \n          \"aa.bp\" = 0, \n          \"aa.ba\" = 0 , \n          \"aa.oe\" = 0, \n          \"aa.op\" = 0, \n          \"aa.oa\" = 0, \n          \"be.oe\" = 0, \n          \"be.op\" = -0.058, \n          \"be.oa\" = 0, \n          \"bp.oe\" = -0.07, \n          \"bp.op\" = 0, \n          \"bp.oa\" = 0, \n          \"ba.oe\" = 0, \n          \"ba.op\" = 0, \n          \"ba.oa\" = 0, \n          \"ae.be.oe\" = 0, \n          \"ae.be.op\" = 0, \n          \"ae.be.oa\" = 0, \n          \"ae.bp.oe\" = 0, \n          \"ae.bp.op\" = 0, \n          \"ae.bp.oa\" = 0, \n          \"ae.ba.oe\" = 0, \n          \"ae.ba.op\" = 0, \n          \"ae.ba.oa\" = 0, \n          \"ap.be.oe\" = 0, \n          \"ap.be.op\" = 0, \n          \"ap.be.oa\" = 0, \n          \"ap.bp.oe\" = 0, \n          \"ap.bp.op\" = 0, \n          \"ap.bp.oa\" = 0, \n          \"ap.ba.oe\" = 0, \n          \"ap.ba.op\" = 0, \n          \"ap.ba.oa\" = 0, \n          \"aa.be.oe\" = 0, \n          \"aa.be.op\" = 0, \n          \"aa.be.oa\" = 0, \n          \"aa.bp.oe\" = 0, \n          \"aa.bp.op\" = 0, \n          \"aa.bp.oa\" = 0, \n          \"aa.ba.oe\" = 0, \n          \"aa.ba.op\" = 0, \n          \"aa.ba.oa\" = 0)\n          \ncoefficients <- data.frame(index = 1:64,sim.B)\nggplot(coefficients, aes(x = index, y = sim.B, label=rownames(coefficients), size = 5, alpha = 0.4)) + geom_point() + geom_text(size = 5, y = sim.B + 0.015) + xlim(c(-5,70)) + theme(text=element_text(size=14),legend.position=\"none\") + ylab(\"Coefficient\")\n\n############################\n# SIMULATED DATA FROM MODEL#\n############################\n\n#I want the data generated from the true model to have characteristics similar to the duke10 data\nduke10 <- read.csv(\"~/GitHub/affectcontroltheory/Data Merged by Event/duke10_by_event.csv\")\n\ncorrplot(cor(duke10[,c(\"ae\",\"ap\",\"aa\",\"be\",\"bp\",\"ba\",\"oe\",\"op\",\"oa\")]))\n\n#covariate means\nX.mean=matrix(colMeans(duke10[,c(\"ae\",\"ap\",\"aa\",\"be\",\"bp\",\"ba\",\"oe\",\"op\",\"oa\")]))\n#covariate SD\nX.var=var(duke10[,c(\"ae\",\"ap\",\"aa\",\"be\",\"bp\",\"ba\",\"oe\",\"op\",\"oa\")])\n\n#simulated covariates\nsim.X1= rmvnorm(1000,X.mean,X.var)\ncolnames(sim.X1) <- colnames(duke10[,10:18])\n\n# TWO-WAY CROSS WORD INTERACTIONS\nsim.X1.interaction = as.matrix(t(apply(sim.X1,1,combn,2,prod)))\ncolnames(sim.X1.interaction)=paste(combn(names(duke10[,10:18]),2,paste,collapse=\".\"),sep=\"\")\nsim.X1.interaction.2=sim.X1.interaction[,c(-1,-2,-9,-22,-23,-27,-34,-35,-36)]\n\n# THREE WAY CROSS WORD INTERACTIONS\n\n#first, generate all three-way interaction names\nsim.X1.3.names.full=paste(combn(names(duke10[,10:18]),3,paste,collapse=\".\"),sep=\"\")\n\n#for-loop looks through all the interaction names and stores only those which are cross-word interactions\nsim.X1.3.names = matrix(nrow = 84, ncol =2)\nfor (i in 1:length(sim.X1.3.names.full)){\n  interaction=sim.X1.3.names.full[i]\n  words = c(substr(interaction,1,1),substr(interaction,4,4),substr(interaction,7,7))\n  if(!is.na(sum(pmatch(c(\"a\",\"b\",\"o\"),words)))){\n    sim.X1.3.names[i,] <- c(interaction,TRUE)\n    print(interaction)\n  }\n  else{\n    sim.X1.3.names[i,] <- c(\"\",FALSE)\n  }\n}\n\n#then, calculate the interactions and use the names to select which ones to keep\nsim.X1.interaction.3 <- as.matrix(t(apply(sim.X1,1,combn,3,prod)))[,sim.X1.3.names[,2]==\"TRUE\"]\ncolnames(sim.X1.interaction.3)=sim.X1.3.names[which(sim.X1.3.names[,2]==\"TRUE\"),1]\n\n# COMBINE TWO-WAY AND THREE-WAY INTERACTIONS\nsim.X1.design.matrix = (cbind(1,sim.X1,sim.X1.interaction.2,sim.X1.interaction.3))\n\n\n#let the sd of the random error come from a lm on the real data\nmodel.summary <- lm(eae ~. , data = duke10[,c(\"eae\", \"ae\",\"ap\",\"aa\",\"be\",\"bp\",\"ba\",\"oe\",\"op\",\"oa\")]) %>% summary()\nY.sd <- model.summary$sigma\n\n#GENERATE FAKE DATA FROM MODEL\n#here we add intercept\nsim.Y=matrix(rmvnorm(1,sim.X1.design.matrix%*%sim.B,diag(Y.sd^2,1000)),ncol=1)\n\n# COMPARE SIMULATED DATA WITH REAL DATA, actor evaluation in-event\nsd(sim.Y)\nsd(duke10$eae)\n\n#minus the intercept\nsim.X1.design.dataframe <- data.frame(sim.X1.design.matrix)\ncorrplot(cor(sim.X1.design.dataframe[,c(\"ae\",\"ap\",\"aa\",\"be\",\"bp\",\"ba\",\"oe\",\"op\",\"oa\")]))\ncorrplot(cor(duke10[,c(\"ae\",\"ap\",\"aa\",\"be\",\"bp\",\"ba\",\"oe\",\"op\",\"oa\")]))\n\n####################\n# CONDUCT ANALYSIS #\n####################\n\nsim.data <- data.frame(cbind(eae=sim.Y,sim.X1.design.matrix))\nnames(sim.data) <- c(\"response\",\"intercept\",names(sim.data)[c(-1,-2)])\n\n#sample observations for training set\ntraining.size <- 500\nselect.training.set <- sample(1:1000,training.size)\n\n#train.data, a training set consisting of 150 observations\ntrain.data <- sim.data[select.training.set,]\n#test.data, a test set consisting of 850 observations\ntest.data <- sim.data[-select.training.set,]\n\n#OLS REGRESSION\nsim.model.ols = lm(response~.,data=train.data[,-2])\nsummary(sim.model.ols)\n\n#STEPWISE REGRESSION\nsim.model.stepwise = step(sim.model.ols)\nsummary(sim.model.stepwise)\n#store identified variables\nvar.iden.stepwise <- names(sim.model.stepwise$coefficients)[-1]\n\n#BAYESIAN MODEL AVERAGING\n\n#unfortunately can't specify prior probability\nsim.model.BMA <- bicreg(x = train.data[,c(-1,-2)], y = train.data[,\"response\"], maxCol=30)\nsummary(sim.model.BMA)\n#store identified variables\nvar.iden.BMA <- sim.model.BMA$namesx[sim.model.BMA$probne0>50]\n\n#HEISE ANOVA ANALYSIS\nhead(train.data)\n\n#select the main factors and get medians for the columns\ntrain.data.main.factors <- select(train.data,response,ae,ap,aa,be,bp,ba,oe,op,oa)\nmainFactorMedians <- select(train.data.main.factors,ae,ap,aa,be,bp,ba,oe,op,oa)%>%apply(MARGIN=2, FUN=median)\n\n#then, dichotomize these main facctors\n#note, mutation written out manually for clarity\ntrain.data.dichotomized <-\n  mutate(train.data.main.factors, \n       ae = ae > mainFactorMedians[\"ae\"],\n       ap = ap > mainFactorMedians[\"ap\"],\n       aa = aa > mainFactorMedians[\"aa\"],\n       be = be > mainFactorMedians[\"be\"],\n       bp = bp > mainFactorMedians[\"bp\"],\n       ba = ba > mainFactorMedians[\"ba\"],\n       oe = oe > mainFactorMedians[\"oe\"],\n       op = op > mainFactorMedians[\"op\"],\n       oa = oa > mainFactorMedians[\"oa\"],) \n\nhead(train.data.dichotomized)\n\n#generate interaction terms from names in the train.data\n#requires \\\\., regular expression for \".\"\nformula <- gsub(\"\\\\.\",\"*\",names(train.data)[c(-1,-2)]) %>% paste(collapse = \"+\")\nformula\n\n#conduct anova\nanova.model <- aov(response ~ ae+ap+aa+be+bp+ba+oe+op+oa+ae*be+ae*bp+ae*ba+ae*oe+ae*op+ae*oa+ap*be+ap*bp+ap*ba+ap*oe+ap*op+ap*oa+aa*be+aa*bp+aa*ba+aa*oe+aa*op+aa*oa+be*oe+be*op+be*oa+bp*oe+bp*op+bp*oa+ba*oe+ba*op+ba*oa+ae*be*oe+ae*be*op+ae*be*oa+ae*bp*oe+ae*bp*op+ae*bp*oa+ae*ba*oe+ae*ba*op+ae*ba*oa+ap*be*oe+ap*be*op+ap*be*oa+ap*bp*oe+ap*bp*op+ap*bp*oa+ap*ba*oe+ap*ba*op+ap*ba*oa+aa*be*oe+aa*be*op+aa*be*oa+aa*bp*oe+aa*bp*op+aa*bp*oa+aa*ba*oe+aa*ba*op+aa*ba*oa, data = train.data.dichotomized)\nsummary(anova.model)\n\n#get p-values from anova\n#ignore the \"residual\" output\nvar.iden.anova <- (rownames(anova(anova.model))[-64])[ anova(anova.model)$'Pr(>F)'[-64] < 0.01 ]\n\n#COMPARE VARIABLES IDENTIFIED WITH ORIGINAL MODEL\nvar.iden.stepwise\nvar.iden.BMA\nvar.iden.anova\n\n#minus the intercept\nvar.model <- names(sim.B)[sim.B!=0][-1]\n\nchecker <- function(identified.variables, true.variables){\n  truePos <- sum(identified.variables %in% true.variables)\n  falsePos <- sum(! identified.variables %in% true.variables)\n  falseNeg <- sum(! true.variables %in% identified.variables)\n  trueNeg <- 63 - truePos - falsePos - falseNeg\n  print(paste(\"True positive:\", truePos))\n  print(paste(\"False positive:\", falsePos))\n  print(paste(\"False negative:\", falseNeg))\n  print(paste(\"True negative:\", trueNeg))\n  print(paste(\"Sensitivity:\", round(truePos/(truePos+falseNeg),digits=2)))\n  print(paste(\"Specificity:\", round(trueNeg/(trueNeg + falsePos),digits=2)))\n}\n\nchecker(var.iden.stepwise,var.model)\nchecker(var.iden.BMA,var.model)\nchecker(var.iden.anova,var.model)\n\n\n\n\n\n",
    "created" : 1409063535417.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "487223229",
    "id" : "10504699",
    "lastKnownWriteTime" : 1409540708,
    "path" : "~/GitHub/affectControlTheory/simulation/simulation.R",
    "project_path" : "simulation.R",
    "properties" : {
        "tempName" : "Untitled1"
    },
    "source_on_save" : false,
    "type" : "r_source"
}