# "DESIGN PHASE" #
##################
#This section is known as the "design phase"
#because we attempt to balance the covariates
#between the treatment and control groups,
#much like we would in an actual experiment.
#Of course, in an actual experiment,
#we don't know the outcomes, so we also remove them.
# Remove outcomes
data.without.outcomes <- data[,-2]
# ESTIMATE PROPENSITY SCORES
# fit logistic regression with interaction terms and quadratics
fullmodel <- glm(NJ.PA ~ .^2 + I(WagePre^2) + I(EmploymentPre^2),data.without.outcomes,family="binomial")
# stepwise regression is used here because overfitting is not a concern
# our objective is to use propensity scores to balance the covariates
# finding the best possible (overfitted) model allows us to balance covariates most effectively
ps.model <- step(fullmodel,
scope = list(lower = ~EmploymentPre+WagePre+BurgerKing+KFC+Roys, upper = ~.)) #stepwise regression to
ps <- predict(ps.model, type="response") #gets the propensity scores for each unit, based on the model
data.without.outcomes <- cbind(data.without.outcomes,ps, treatment = ifelse(data.without.outcomes$NJ.PA==1,"New Jersey","Pennsylvania"))
# PLOT PROPENSITY SCORES OF TREATMENT AND CONTROL GROUPS
# does group? work? can use in ggplot2
#turns out you can use add_data?
subset(data.without.outcomes, subset = NJ.PA==0)  %>% ggvis(~ps)%>% layer_densities(stroke := "blue", fill := "none")%>%add_data(subset(data.without.outcomes, subset = NJ.PA==1)) %>% layer_densities(stroke :="red", fill := "none")
#NOTE: VERY PICKY ABOUT WHAT GETS PASSED TO ARGUMENTS
#MUST BE CATEGORICAL FOR GROUP BY TO WORK!
ggvis(data=data.without.outcomes, x = ~ps) %>% group_by(treatment) %>% layer_densities(fill := "none", stroke = ~treatment)
#so it appears that there is good balance
data.trimmed=trimIterate(ps.model,data,data$NJ.PA)
data.trimmed.model = glm(formula(ps.model),data.trimmed,family="binomial")
ps.trimmed = predict(data.trimmed.model)
data <- cbind(data,ps.trimmed, treatment = ifelse(data$NJ.PA==1,"New Jersey","Pennsylvania"))
data <- cbind(data.trimmed,ps.trimmed, treatment = ifelse(data.trimmed$NJ.PA==1,"New Jersey","Pennsylvania"))
ggvis(data=data.trimmed, x = ~ps.trimmed) %>% group_by(treatment) %>% layer_densities(fill := "none", stroke = ~treatment)
###########################
# TESTING GGVIS OUT USING #
# MINIMUM WAGE DATA       #
###########################
#SOURCE UTILITY FUNCTIONS
source("~/GitHub/ggvisTest/utility.R")
#READ-IN DATA
data <- read.csv("~/GitHub/ggvisTest/Minimum Wage - Sheet1.csv")
#IMPORT GGVIS
require(ggvis)
##################
# "DESIGN PHASE" #
##################
#This section is known as the "design phase"
#because we attempt to balance the covariates
#between the treatment and control groups,
#much like we would in an actual experiment.
#Of course, in an actual experiment,
#we don't know the outcomes, so we also remove them.
# Remove outcomes
data.without.outcomes <- data[,-2]
# ESTIMATE PROPENSITY SCORES
# fit logistic regression with interaction terms and quadratics
fullmodel <- glm(NJ.PA ~ .^2 + I(WagePre^2) + I(EmploymentPre^2),data.without.outcomes,family="binomial")
# stepwise regression is used here because overfitting is not a concern
# our objective is to use propensity scores to balance the covariates
# finding the best possible (overfitted) model allows us to balance covariates most effectively
ps.model <- step(fullmodel,
scope = list(lower = ~EmploymentPre+WagePre+BurgerKing+KFC+Roys, upper = ~.)) #stepwise regression to
ps <- predict(ps.model, type="response") #gets the propensity scores for each unit, based on the model
data.without.outcomes <- cbind(data.without.outcomes,ps, treatment = ifelse(data.without.outcomes$NJ.PA==1,"New Jersey","Pennsylvania"))
# PLOT PROPENSITY SCORES OF TREATMENT AND CONTROL GROUPS
# does group? work? can use in ggplot2
#turns out you can use add_data?
subset(data.without.outcomes, subset = NJ.PA==0)  %>% ggvis(~ps)%>% layer_densities(stroke := "blue", fill := "none")%>%add_data(subset(data.without.outcomes, subset = NJ.PA==1)) %>% layer_densities(stroke :="red", fill := "none")
#NOTE: VERY PICKY ABOUT WHAT GETS PASSED TO ARGUMENTS
#MUST BE CATEGORICAL FOR GROUP BY TO WORK!
ggvis(data=data.without.outcomes, x = ~ps) %>% group_by(treatment) %>% layer_densities(fill := "none", stroke = ~treatment)
#so it appears that there is good balance
#TRIM DATA
data.trimmed=trimIterate(ps.model,data,data$NJ.PA)
# OBTAIN NEW PROPENSITY SCORE ESTIMATES
data.trimmed.model = glm(formula(ps.model),data.trimmed,family="binomial")
ps.trimmed = predict(data.trimmed.model)
# REBIND PROPENSITY SCORES AND TREATMENT INDICATOR TO DATA
data.trimmed <- cbind(data.trimmed,ps.trimmed, treatment = ifelse(data.trimmed$NJ.PA==1,"New Jersey","Pennsylvania"))
ggvis(data=data.trimmed, x = ~ps.trimmed) %>% group_by(treatment) %>% layer_densities(fill := "none", stroke = ~treatment)
ggvis(data=data.trimmed, x = ~ps.trimmed) %>% group_by(treatment) %>% layer_densities(fill := "none", stroke = ~treatment) %>% layer_text(fontSize := 12)
ggvis(data=data.trimmed, x = ~ps.trimmed) %>% group_by(treatment) %>% layer_densities(fill := "none", stroke = ~treatment) %>% add_legend(fontSize := 12)
ggvis(data=data.trimmed, x = ~ps.trimmed) %>% group_by(treatment) %>% layer_densities(fill := "none", stroke = ~treatment) %>% add_legend(fontSize = 12)
ggvis(data=data.trimmed, x = ~ps.trimmed, fontSize = 30) %>% group_by(treatment) %>% layer_densities(fill := "none", stroke = ~treatment)
ggvis(data=data.trimmed, x = ~ps.trimmed, xlab="Linear Propensity Scores") %>% group_by(treatment) %>% layer_densities(fill := "none", stroke = ~treatment)
ggvis(data=data.trimmed, x = ~ps.trimmed) %>% group_by(treatment) %>% layer_densities(fill := "none", stroke = ~treatment) %>% add_axis("x", title = "Linear Propensity Scores")
ggvis(data=data.trimmed, x = ~ps.trimmed) %>%
group_by(treatment) %>%
layer_densities(fill := "none", stroke = ~treatment) %>%
add_axis("x", title = "Linear Propensity Scores",
properties = axis_props(labels = list(fontSize=20)))
ggvis(data=data.trimmed, x = ~ps.trimmed) %>%
group_by(treatment) %>%
layer_densities(fill := "none", stroke = ~treatment) %>%
add_axis("x", title = "Linear Propensity Scores")
ggvis(data=data.trimmed, x = ~ps.trimmed) %>%
group_by(treatment, fontSize=20) %>%
layer_densities(fill := "none", stroke = ~treatment) %>%
add_axis("x", title = "Linear Propensity Scores")
ggvis(data=data.trimmed, x = ~ps.trimmed) %>%
group_by(treatment) %>%
layer_densities(fill := "none", stroke = ~treatment) %>%
add_axis("x", title = "Linear Propensity Scores", fontSize = 20)
###########################
# TESTING GGVIS OUT USING #
# MINIMUM WAGE DATA       #
###########################
#SOURCE UTILITY FUNCTIONS
source("~/GitHub/ggvisTest/utility.R")
#READ-IN DATA
data <- read.csv("~/GitHub/ggvisTest/Minimum Wage - Sheet1.csv")
#IMPORT GGVIS
require(ggvis)
##################
# "DESIGN PHASE" #
##################
#This section is known as the "design phase"
#because we attempt to balance the covariates
#between the treatment and control groups,
#much like we would in an actual experiment.
#Of course, in an actual experiment,
#we don't know the outcomes, so we also remove them.
# Remove outcomes
data.without.outcomes <- data[,-2]
# ESTIMATE PROPENSITY SCORES
# fit logistic regression with interaction terms and quadratics
fullmodel <- glm(NJ.PA ~ .^2 + I(WagePre^2) + I(EmploymentPre^2),data.without.outcomes,family="binomial")
# stepwise regression is used here because overfitting is not a concern
# our objective is to use propensity scores to balance the covariates
# finding the best possible (overfitted) model allows us to balance covariates most effectively
ps.model <- step(fullmodel,
scope = list(lower = ~EmploymentPre+WagePre+BurgerKing+KFC+Roys, upper = ~.)) #stepwise regression to
ps <- predict(ps.model, type="response") #gets the propensity scores for each unit, based on the model
data.without.outcomes <- cbind(data.without.outcomes,ps, treatment = ifelse(data.without.outcomes$NJ.PA==1,"New Jersey","Pennsylvania"))
# PLOT PROPENSITY SCORES OF TREATMENT AND CONTROL GROUPS
# does group? work? can use in ggplot2
#turns out you can use add_data?
subset(data.without.outcomes, subset = NJ.PA==0)  %>% ggvis(~ps)%>% layer_densities(stroke := "blue", fill := "none")%>%add_data(subset(data.without.outcomes, subset = NJ.PA==1)) %>% layer_densities(stroke :="red", fill := "none")
#NOTE: VERY PICKY ABOUT WHAT GETS PASSED TO ARGUMENTS
#MUST BE CATEGORICAL FOR GROUP BY TO WORK!
ggvis(data=data.without.outcomes, x = ~ps) %>% group_by(treatment) %>% layer_densities(fill := "none", stroke = ~treatment)
#so it appears that there is good balance
#TRIM DATA
data.trimmed=trimIterate(ps.model,data,data$NJ.PA)
# OBTAIN NEW PROPENSITY SCORE ESTIMATES
data.trimmed.model = glm(formula(ps.model),data.trimmed,family="binomial")
ps.trimmed = predict(data.trimmed.model)
# REBIND PROPENSITY SCORES AND TREATMENT INDICATOR TO DATA
data.trimmed <- cbind(data.trimmed,ps = ps.trimmed, treatment = ifelse(data.trimmed$NJ.PA==1,"New Jersey","Pennsylvania"))
ggvis(data=data.trimmed, x = ~ps.trimmed) %>%
group_by(treatment) %>%
layer_densities(fill := "none", stroke = ~treatment) %>%
add_axis("x", title = "Linear Propensity Scores")
ggvis(data=data.trimmed, x = ~ps) %>%
group_by(treatment) %>%
layer_densities(fill := "none", stroke = ~treatment) %>%
add_axis("x", title = "Linear Propensity Scores")
?input_radiobuttons
selectedData <- input_radiobuttons(choices=list(data.without.outcomes, data.trimmed))
selectedData <- input_radiobuttons(choices=c(data.without.outcomes, data.trimmed))
selectedData <- input_radiobuttons(choices=c(data.without.outcomes, data.trimmed), selected=1)
warnings()
selectedData <- input_radiobuttons(choices=c("Untrimmed Data" = data.without.outcomes, "Trimmed Data" = data.trimmed))
selectedData <- input_radiobuttons(choices=c("Untrimmed Data" = data.without.outcomes, "Trimmed Data" = data.trimmed), selected = data.without.outcomes)
selectedData <- input_select(choices=c("Untrimmed Data" = data.without.outcomes, "Trimmed Data" = data.trimmed))
ggvis(data=selectedData, x = ~ps) %>%
group_by(treatment) %>%
layer_densities(fill := "none", stroke = ~treatment) %>%
add_axis("x", title = "Linear Propensity Scores")
selectedData
ggvis(data=selectedData[1], x = ~ps) %>%
group_by(treatment) %>%
layer_densities(fill := "none", stroke = ~treatment) %>%
add_axis("x", title = "Linear Propensity Scores")
ggvis(data=data.trimmed, x = ~ps) %>%
group_by(treatment) %>%
layer_densities(fill := "none", stroke = ~treatment) %>%
add_axis("x", title = "Linear Propensity Scores")
require(reshape)
install.packages("reshape")
require(reshape)
install.packages("reshape2")
install.packages("reshape2")
require(reshape2)
install.packages("reshape2")
install.packages("reshape2")
!
ggvis(data=data.without.outcomes, x = ~ps) %>% group_by(treatment) %>% layer_densities(fill := "none", stroke = ~treatment)
###########################
# TESTING GGVIS OUT USING #
# MINIMUM WAGE DATA       #
###########################
#SOURCE UTILITY FUNCTIONS
source("~/GitHub/ggvisTest/utility.R")
#READ-IN DATA
data <- read.csv("~/GitHub/ggvisTest/Minimum Wage - Sheet1.csv")
#IMPORT GGVIS
require(ggvis)
require(reshape2)
##################
# "DESIGN PHASE" #
##################
#This section is known as the "design phase"
#because we attempt to balance the covariates
#between the treatment and control groups,
#much like we would in an actual experiment.
#Of course, in an actual experiment,
#we don't know the outcomes, so we also remove them.
# Remove outcomes
data.without.outcomes <- data[,-2]
# ESTIMATE PROPENSITY SCORES
# fit logistic regression with interaction terms and quadratics
fullmodel <- glm(NJ.PA ~ .^2 + I(WagePre^2) + I(EmploymentPre^2),data.without.outcomes,family="binomial")
# stepwise regression is used here because overfitting is not a concern
# our objective is to use propensity scores to balance the covariates
# finding the best possible (overfitted) model allows us to balance covariates most effectively
ps.model <- step(fullmodel,
scope = list(lower = ~EmploymentPre+WagePre+BurgerKing+KFC+Roys, upper = ~.)) #stepwise regression to
ps <- predict(ps.model, type="response") #gets the propensity scores for each unit, based on the model
data.without.outcomes <- cbind(data.without.outcomes,ps, treatment = ifelse(data.without.outcomes$NJ.PA==1,"New Jersey","Pennsylvania"))
# PLOT PROPENSITY SCORES OF TREATMENT AND CONTROL GROUPS
# does group? work? can use in ggplot2
#turns out you can use add_data?
subset(data.without.outcomes, subset = NJ.PA==0)  %>% ggvis(~ps)%>% layer_densities(stroke := "blue", fill := "none")%>%add_data(subset(data.without.outcomes, subset = NJ.PA==1)) %>% layer_densities(stroke :="red", fill := "none")
#NOTE: VERY PICKY ABOUT WHAT GETS PASSED TO ARGUMENTS
#MUST BE CATEGORICAL FOR GROUP BY TO WORK!
ggvis(data=data.without.outcomes, x = ~ps) %>% group_by(treatment) %>% layer_densities(fill := "none", stroke = ~treatment)
#so it appears that there is good balance
#TRIM DATA
data.trimmed=trimIterate(ps.model,data,data$NJ.PA)
# OBTAIN NEW PROPENSITY SCORE ESTIMATES
data.trimmed.model = glm(formula(ps.model),data.trimmed,family="binomial")
ps.trimmed = predict(data.trimmed.model)
# REBIND PROPENSITY SCORES AND TREATMENT INDICATOR TO DATA
data.trimmed <- cbind(data.trimmed,ps = ps.trimmed, treatment = ifelse(data.trimmed$NJ.PA==1,"New Jersey","Pennsylvania"))
ggvis(data=data.trimmed, x = ~ps) %>%
group_by(treatment) %>%
layer_densities(fill := "none", stroke = ~treatment) %>%
add_axis("x", title = "Linear Propensity Scores")
selectedData <- input_select(choices=c("Untrimmed Data" = data.without.outcomes, "Trimmed Data" = data.trimmed))
ggvis(data=data.trimmed, x = ~ps) %>%
group_by(treatment) %>%
layer_densities(fill := "none", stroke = ~treatment) %>%
add_axis("x", title = "Linear Propensity Scores")
comparePS <- melt(data.without.outcomes[,c("treatment","ps")],data.trimmed[,c("treatment","ps")])
dim(data.without.outcomes)
dim(data.trimmed)
comparePS <- melt(cbind(data.without.outcomes[,c("treatment","ps")],id="original"),
cbind(data.trimmed[,c("treatment","ps")], id="trimmed"),
id.vars = "id")
cbind(data.without.outcomes[,c("treatment","ps")],id="original")
comparePS <- melt(cbind(data.without.outcomes[,c("treatment","ps")],id="original"),
cbind(data.trimmed[,c("treatment","ps")], id="trimmed"),
id.vars = "id",
measure.vars = c("treatment","ps"))
#Melt data to tidy it up
comparePS <- melt(cbind(data.without.outcomes[,c("treatment","ps")],id="original"),
cbind(data.trimmed[,c("treatment","ps")], id="trimmed"),
id.vars = c("id","treatment"),
measure.vars = c("ps"))
#Melt data to tidy it up
comparePS <- melt(cbind(data.without.outcomes[,c("treatment","ps")],id="original"),
cbind(data.trimmed[,c("treatment","ps")], id="trimmed"),
id.vars = c("id","treatment"))
#Melt data to tidy it up
comparePS <- melt(data1 = cbind(data.without.outcomes[,c("treatment","ps")],id="original"),
data2 = cbind(data.trimmed[,c("treatment","ps")], id="trimmed"),
id.vars = c("id","treatment"))
?melt
data.trimmed[,c("treatment","ps")]
###########################
# TESTING GGVIS OUT USING #
# MINIMUM WAGE DATA       #
###########################
#SOURCE UTILITY FUNCTIONS
source("~/GitHub/ggvisTest/utility.R")
#READ-IN DATA
data <- read.csv("~/GitHub/ggvisTest/Minimum Wage - Sheet1.csv")
#IMPORT GGVIS
require(ggvis)
require(reshape2)
#TIDY THE DATA
###########################
# TESTING GGVIS OUT USING #
# MINIMUM WAGE DATA       #
###########################
#SOURCE UTILITY FUNCTIONS
source("~/GitHub/ggvisTest/utility.R")
#READ-IN DATA
data <- read.csv("~/GitHub/ggvisTest/Minimum Wage - Sheet1.csv")
#IMPORT GGVIS
require(ggvis)
require(reshape2)
#TIDY THE DATA
summary(data)
data.melted <- melt(data, id.vars = c("NJ.PA","BurgerKing","KFC","Roys","Wendys"))
data.melted
require(dplyr)
data.melted <- melt(data, id.vars = c("NJ.PA","BurgerKing","KFC","Roys","Wendys"))
data.melted
data.melted[1:10,]
melt(data, id.vars = c("NJ.PA","BurgerKing","KFC","Roys","Wendys"))
summary(data)
data.melted <- melt(data, id.vars = c("NJ.PA","BurgerKing","KFC","Roys","Wendys"))
data.melted[1:10,]
head(data.melted)
data.melted[,c(2:5)]
?apply
names(data)
c("Burger King", "KFC", "Roys", "Wendys")[c(0,0,0,1)]
c("Burger King", "KFC", "Roys", "Wendys")[c(0,0,1,0)]
c("Burger King", "KFC", "Roys", "Wendys")[,c(0,0,1,0)]
c("Burger King", "KFC", "Roys", "Wendys")[c(0,0,1,0)%*%c(1,2,3,4)]
restaurant <- function(x) c("Burger King", "KFC", "Roys", "Wendys")[c(0,0,1,0)%*%c(1,2,3,4)]
apply(data.melted[,c(2:5)], MARGIN =1, restaurant)
restaurant <- function(x) c("Burger King", "KFC", "Roys", "Wendys")[x%*%c(1,2,3,4)]
apply(data.melted[,c(2:5)], MARGIN =1, restaurant)
restaurantPicker <- function(x) c("Burger King", "KFC", "Roys", "Wendys")[x%*%c(1,2,3,4)]
restaurant <- apply(data.melted[,c(2:5)], MARGIN =1, restaurantPicker)
names(data.melted)
data.melted <- cbind(state = data.melted$NJ.PA, restaurant, data.melted$variable, data.melted$value)
###########################
# TESTING GGVIS OUT USING #
# MINIMUM WAGE DATA       #
###########################
#SOURCE UTILITY FUNCTIONS
source("~/GitHub/ggvisTest/utility.R")
#READ-IN DATA
data <- read.csv("~/GitHub/ggvisTest/Minimum Wage - Sheet1.csv")
#IMPORT GGVIS
require(ggvis)
require(reshape2)
require(dplyr)
#DESCRIPTION OF RAW DATA
# NJ.PA, indicator for whether or not restaurant is in NJ
# EmploymentPost, EmploymentPre, how many people employed at restaurant at beginning and end of study period
# WagePre, wage before
# Burger King, KFC, Roys, Wendys, type of restaurant
#TIDY THE DATA
data.melted <- melt(data, id.vars = c("NJ.PA","BurgerKing","KFC","Roys","Wendys"))
head(data.melted)
restaurantPicker <- function(x) c("Burger King", "KFC", "Roys", "Wendys")[x%*%c(1,2,3,4)]
restaurant <- apply(data.melted[,c("Burger King", "KFC", "Roys", "Wendys")], MARGIN =1, restaurantPicker)
data.melted <- cbind(state = data.melted$NJ.PA, restaurant, data.melted$variable, data.melted$value)
head(data.melted)
restaurant <- apply(data.melted[,c("BurgerKing", "KFC", "Roys", "Wendys")], MARGIN =1, restaurantPicker)
data.melted <- cbind(state = data.melted$NJ.PA, restaurant, data.melted$variable, data.melted$value)
head(data.melted)
###########################
# TESTING GGVIS OUT USING #
# MINIMUM WAGE DATA       #
###########################
#SOURCE UTILITY FUNCTIONS
source("~/GitHub/ggvisTest/utility.R")
#READ-IN DATA
data <- read.csv("~/GitHub/ggvisTest/Minimum Wage - Sheet1.csv")
#IMPORT GGVIS
require(ggvis)
require(reshape2)
require(dplyr)
#DESCRIPTION OF RAW DATA
# NJ.PA, indicator for whether or not restaurant is in NJ
# EmploymentPost, EmploymentPre, how many people employed at restaurant at beginning and end of study period
# WagePre, wage before
# Burger King, KFC, Roys, Wendys, type of restaurant
#TIDY THE DATA
data.melted <- melt(data, id.vars = c("NJ.PA","BurgerKing","KFC","Roys","Wendys"))
head(data.melted)
#merge restaurant indicators into restaurant variable
restaurantPicker <- function(x) c("Burger King", "KFC", "Roys", "Wendys")[x%*%c(1,2,3,4)]
restaurant <- apply(data.melted[,c("BurgerKing", "KFC", "Roys", "Wendys")], MARGIN =1, restaurantPicker)
data.melted <- cbind(state = ifelse(data.melted$NJ.PA==1, "New Jersey", "Pennsylvania"), restaurant, data.melted$variable, data.melted$value)
head(data.melted)
###########################
# TESTING GGVIS OUT USING #
# MINIMUM WAGE DATA       #
###########################
#SOURCE UTILITY FUNCTIONS
source("~/GitHub/ggvisTest/utility.R")
#READ-IN DATA
data <- read.csv("~/GitHub/ggvisTest/Minimum Wage - Sheet1.csv")
#IMPORT GGVIS
require(ggvis)
require(reshape2)
require(dplyr)
#DESCRIPTION OF RAW DATA
# NJ.PA, indicator for whether or not restaurant is in NJ
# EmploymentPost, EmploymentPre, how many people employed at restaurant at beginning and end of study period
# WagePre, wage before
# Burger King, KFC, Roys, Wendys, type of restaurant
#TIDY THE DATA
data.melted <- melt(data, id.vars = c("NJ.PA","BurgerKing","KFC","Roys","Wendys"))
head(data.melted)
data.melted2 <- cbind(state = ifelse(data.melted$NJ.PA==1, "New Jersey", "Pennsylvania"), restaurant, data.melted$variable, data.melted$value)
head(data.melted2)
data.melted2 <- cbind(state = ifelse(data.melted$NJ.PA==1, "New Jersey", "Pennsylvania"), restaurant, data.melted[,c("variable", "value")])
head(data.melted2)
###########################
# TESTING GGVIS OUT USING #
# MINIMUM WAGE DATA       #
###########################
#SOURCE UTILITY FUNCTIONS
source("~/GitHub/ggvisTest/utility.R")
#READ-IN DATA
data <- read.csv("~/GitHub/ggvisTest/Minimum Wage - Sheet1.csv")
#IMPORT GGVIS
require(ggvis)
require(reshape2)
require(dplyr)
#DESCRIPTION OF RAW DATA
# NJ.PA, indicator for whether or not restaurant is in NJ
# EmploymentPost, EmploymentPre, how many people employed at restaurant at beginning and end of study period
# WagePre, wage before
# Burger King, KFC, Roys, Wendys, type of restaurant
#TIDY THE DATA
data.melted.temp <- melt(data, id.vars = c("NJ.PA","BurgerKing","KFC","Roys","Wendys"))
head(data.melted)
#merge restaurant indicators into restaurant variable
restaurantPicker <- function(x) c("Burger King", "KFC", "Roys", "Wendys")[x%*%c(1,2,3,4)]
restaurant <- apply(data.melted.temp[,c("BurgerKing", "KFC", "Roys", "Wendys")], MARGIN =1, restaurantPicker)
data.melted <- cbind(state = ifelse(data.melted.temp$NJ.PA==1, "New Jersey", "Pennsylvania"), restaurant, data.melted.temp[,c("variable", "value")])
head(data.melted)
##################
# "DESIGN PHASE" #
##################
#This section is known as the "design phase"
#because we attempt to balance the covariates
#between the treatment and control groups,
#much like we would in an actual experiment.
###########################
# TESTING GGVIS OUT USING #
# MINIMUM WAGE DATA       #
###########################
#SOURCE UTILITY FUNCTIONS
source("~/GitHub/ggvisTest/utility.R")
#READ-IN DATA
data <- read.csv("~/GitHub/ggvisTest/Minimum Wage - Sheet1.csv")
#IMPORT GGVIS
require(ggvis)
require(reshape2)
require(dplyr)
#DESCRIPTION OF RAW DATA
# NJ.PA, indicator for whether or not restaurant is in NJ
# EmploymentPost, EmploymentPre, how many people employed at restaurant at beginning and end of study period
# WagePre, wage before
# Burger King, KFC, Roys, Wendys, type of restaurant
#TIDY THE DATA
data.melted.temp <- melt(data, id.vars = c("NJ.PA","BurgerKing","KFC","Roys","Wendys"))
head(data.melted.temp)
#merge restaurant indicators into restaurant variable
restaurantPicker <- function(x) c("Burger King", "KFC", "Roys", "Wendys")[x%*%c(1,2,3,4)]
restaurant <- apply(data.melted.temp[,c("BurgerKing", "KFC", "Roys", "Wendys")], MARGIN =1, restaurantPicker)
data.melted <- cbind(state = ifelse(data.melted.temp$NJ.PA==1, "New Jersey", "Pennsylvania"), restaurant, data.melted.temp[,c("variable", "value")])
head(data.melted)
##################
# "DESIGN PHASE" #
##################
#This section is known as the "design phase"
#because we attempt to balance the covariates
#between the treatment and control groups,
#much like we would in an actual experiment.
source("http://stat.duke.edu/courses/Spring14/sta320.01/CausalInference.R")
subclass.var
install.packages("plyr")
install.packages("plyr")
?rmvnorm
?rmvnorm
require(mvtnorm)
?rmvnorm
?apply
?anova
?aov
setwd("~/GitHub/affectControlTheory/Data Merged by Event")
setwd("~/GitHub/affectControlTheory/Raw Data")
duke10 <- read.csv("~/GitHub/affectControlTheory/Raw Data/Duke 2010 FINAL.csv")
View(duke10)
###################################
# EXPLORATORY ANALYSIS OF DUKE 10 #
###################################
require(reshape2)
#The cleaned duke 10 data
duke10 <- read.csv("~/GitHub/affectControlTheory/Raw Data/Duke 2010 ENGLISH - FINAL.csv")
head(duke10)
#we wish to "tidy" the data, where:
?melt
setwd("~/GitHub/affectControlTheory/Raw Data")
require(shiny)
runApp(duke10applet)
runApp("duke10applet")
runApp("duke10applet")
names(duke10)
require(dplyr)
?summarize
summary(duke10$sex)
summarize(duke10[,"sex"])
summarize(male = duke10[,"sex"] == 2)
summarize(male = factor(duke10[,"sex"] == 2)
summarize(male = factor(duke10[,"sex"] == 2))
summarize(male = factor(duke10[,"sex"] == 2))
duke10 %>% group_by(sex) %>% head()
require(ggvis)
names(duke10)
duke10 %>% group_by(sex) %>% ggvis( x = ~ia42) %>% layer_densities()
plot <- ggplot(duke10, aes(x = ia42))
require(ggplot2)
plot <- ggplot(duke10, aes(x = ia42))
p <- ggplot(duke10, aes(x = ia42))
p <- ggplot(duke10, aes(x = ia42))
p + geom_density(aes(stroke = factor(sex)))
p <- ggplot(duke10, aes(x = ia42))
p + geom_density(aes(stroke = factor(sex), color = factor(sex)))
